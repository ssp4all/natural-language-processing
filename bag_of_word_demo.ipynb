{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 946,
     "status": "ok",
     "timestamp": 1549855271028,
     "user": {
      "displayName": "SURAJ PAWAR",
      "photoUrl": "https://lh3.googleusercontent.com/-AyjYqK2CgTs/AAAAAAAAAAI/AAAAAAAAAi0/7DFu2E8Fno8/s64/photo.jpg",
      "userId": "15683806829583900212"
     },
     "user_tz": -330
    },
    "id": "SyVwRhLypNYT",
    "outputId": "21abc421-b885-4c46-b9de-2795b8579a67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5639,
     "status": "ok",
     "timestamp": 1549855298144,
     "user": {
      "displayName": "SURAJ PAWAR",
      "photoUrl": "https://lh3.googleusercontent.com/-AyjYqK2CgTs/AAAAAAAAAAI/AAAAAAAAAi0/7DFu2E8Fno8/s64/photo.jpg",
      "userId": "15683806829583900212"
     },
     "user_tz": -330
    },
    "id": "7Jk6AGEvkpY6",
    "outputId": "99827a84-1459-44c9-9a20-f93f32b5a1fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/ssp/anaconda3/lib/python3.6/site-packages (3.2.5)\n",
      "Requirement already satisfied: six in /home/ssp/.local/lib/python3.6/site-packages (from nltk) (1.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2SDU31RIk094",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "set(stopwords.words('english')) #nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1257,
     "status": "ok",
     "timestamp": 1549858346880,
     "user": {
      "displayName": "SURAJ PAWAR",
      "photoUrl": "https://lh3.googleusercontent.com/-AyjYqK2CgTs/AAAAAAAAAAI/AAAAAAAAAi0/7DFu2E8Fno8/s64/photo.jpg",
      "userId": "15683806829583900212"
     },
     "user_tz": -330
    },
    "id": "cJ4V30INvus9",
    "outputId": "fd78fbee-1747-4af7-d055-80df7db52ec1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ssp/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Aj06sp06wbP0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /home/ssp/anaconda3/lib/python3.6/site-packages (2.0.18)\n",
      "Requirement already satisfied: ujson>=1.35 in /home/ssp/anaconda3/lib/python3.6/site-packages (from spacy) (1.35)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /home/ssp/anaconda3/lib/python3.6/site-packages (from spacy) (0.9.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/ssp/.local/lib/python3.6/site-packages (from spacy) (2.18.4)\n",
      "Requirement already satisfied: thinc<6.13.0,>=6.12.1 in /home/ssp/anaconda3/lib/python3.6/site-packages (from spacy) (6.12.1)\n",
      "Requirement already satisfied: dill<0.3,>=0.2 in /home/ssp/anaconda3/lib/python3.6/site-packages (from spacy) (0.2.9)\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /home/ssp/anaconda3/lib/python3.6/site-packages (from spacy) (2.0.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/ssp/anaconda3/lib/python3.6/site-packages (from spacy) (2.0.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/ssp/anaconda3/lib/python3.6/site-packages (from spacy) (1.16.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/ssp/anaconda3/lib/python3.6/site-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: regex==2018.01.10 in /home/ssp/anaconda3/lib/python3.6/site-packages (from spacy) (2018.1.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ssp/.local/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2017.11.5)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /home/ssp/.local/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.22)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /home/ssp/.local/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ssp/.local/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /home/ssp/anaconda3/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /home/ssp/anaconda3/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy) (4.19.9)\n",
      "Requirement already satisfied: msgpack<0.6.0,>=0.5.6 in /home/ssp/anaconda3/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.5.6)\n",
      "Requirement already satisfied: msgpack-numpy<0.4.4 in /home/ssp/anaconda3/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.4.3.2)\n",
      "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /home/ssp/.local/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.10.10)\n",
      "Requirement already satisfied: six<2.0.0,>=1.10.0 in /home/ssp/.local/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.11.0)\n",
      "Requirement already satisfied: toolz>=0.8.0 in /home/ssp/anaconda3/lib/python3.6/site-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy) (0.9.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KIY9fZgNk074"
   },
   "outputs": [],
   "source": [
    "text = [\"Joe waited for the train\", \"The train was late\", \"Mary and Samantha took the bus\",\n",
    "\"I looked for Mary and Samantha at the bus station\",\n",
    "\"Mary and Samantha arrived at the bus station early but waited until noon for the bus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 950,
     "status": "ok",
     "timestamp": 1549855847984,
     "user": {
      "displayName": "SURAJ PAWAR",
      "photoUrl": "https://lh3.googleusercontent.com/-AyjYqK2CgTs/AAAAAAAAAAI/AAAAAAAAAi0/7DFu2E8Fno8/s64/photo.jpg",
      "userId": "15683806829583900212"
     },
     "user_tz": -330
    },
    "id": "nsW8Ewndk05P",
    "outputId": "1558d963-8f4d-4f8b-ffac-845ac3176bfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Joe waited for the train', 'The train was late', 'Mary and Samantha took the bus', 'I looked for Mary and Samantha at the bus station', 'Mary and Samantha arrived at the bus station early but waited until noon for the bus']\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hp8gPlvMk02p"
   },
   "outputs": [],
   "source": [
    "def word_extraction(sentence):\n",
    "    ignore = ['a', \"the\", \"is\"]\n",
    "    words = re.sub(\"[^\\w]\", \" \",  sentence).split()\n",
    "    cleaned_text = [w.lower() for w in words if w not in ignore]\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1328,
     "status": "ok",
     "timestamp": 1549856782624,
     "user": {
      "displayName": "SURAJ PAWAR",
      "photoUrl": "https://lh3.googleusercontent.com/-AyjYqK2CgTs/AAAAAAAAAAI/AAAAAAAAAi0/7DFu2E8Fno8/s64/photo.jpg",
      "userId": "15683806829583900212"
     },
     "user_tz": -330
    },
    "id": "I-HDqZiOk0yf",
    "outputId": "98919fee-c011-4cc2-f824-70a7df955a34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['joe', 'waited', 'for', 'train']\n",
      "['the', 'train', 'was', 'late']\n",
      "['mary', 'and', 'samantha', 'took', 'bus']\n",
      "['i', 'looked', 'for', 'mary', 'and', 'samantha', 'at', 'bus', 'station']\n",
      "['mary', 'and', 'samantha', 'arrived', 'at', 'bus', 'station', 'early', 'but', 'waited', 'until', 'noon', 'for', 'bus']\n"
     ]
    }
   ],
   "source": [
    "for p in text:\n",
    "    print(word_extraction(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "26LU73uxk0pp"
   },
   "outputs": [],
   "source": [
    "def tokenize(sentences):\n",
    "    words = []\n",
    "    for sentence in sentences:\n",
    "        w = word_extraction(sentence)\n",
    "        words.extend(w)     \n",
    "    words = sorted(list(set(words)))\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 947,
     "status": "ok",
     "timestamp": 1549857215591,
     "user": {
      "displayName": "SURAJ PAWAR",
      "photoUrl": "https://lh3.googleusercontent.com/-AyjYqK2CgTs/AAAAAAAAAAI/AAAAAAAAAi0/7DFu2E8Fno8/s64/photo.jpg",
      "userId": "15683806829583900212"
     },
     "user_tz": -330
    },
    "id": "8h1Ck6A3rNOA",
    "outputId": "75165f02-f80e-4386-f863-e590c5e9deca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'arrived', 'at', 'bus', 'but', 'early', 'for', 'i', 'joe', 'late', 'looked', 'mary', 'noon', 'samantha', 'station', 'the', 'took', 'train', 'until', 'waited', 'was']\n"
     ]
    }
   ],
   "source": [
    "print(tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kYooefFQsZqH"
   },
   "outputs": [],
   "source": [
    "def generate_bow(allsentences):    \n",
    "    vocab = tokenize(allsentences)\n",
    "#     print(\"Word List for Document \\n{0} \\n\".format(vocab));\n",
    "    return vocab\n",
    "    \n",
    "def xyz():\n",
    "    for sentence in text:\n",
    "        words = word_extraction(sentence)\n",
    "        vocab = generate_bow(text)\n",
    "        bag_vector = numpy.zeros(len(vocab))\n",
    "        for w in words:\n",
    "            for i,word in enumerate(vocab):\n",
    "                if word == w: \n",
    "                    bag_vector[i] += 1\n",
    "        print(\"{0}\\n{1}\\n\".format(sentence,numpy.array(bag_vector)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1146,
     "status": "ok",
     "timestamp": 1549857989775,
     "user": {
      "displayName": "SURAJ PAWAR",
      "photoUrl": "https://lh3.googleusercontent.com/-AyjYqK2CgTs/AAAAAAAAAAI/AAAAAAAAAi0/7DFu2E8Fno8/s64/photo.jpg",
      "userId": "15683806829583900212"
     },
     "user_tz": -330
    },
    "id": "IKVOQbULskwL",
    "outputId": "12090f72-6abe-4939-c329-0a1c4f780dcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joe waited for the train\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.]\n",
      "\n",
      "The train was late\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1.]\n",
      "\n",
      "Mary and Samantha took the bus\n",
      "[1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      "\n",
      "I looked for Mary and Samantha at the bus station\n",
      "[1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "Mary and Samantha arrived at the bus station early but waited until noon for the bus\n",
      "[1. 1. 1. 2. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_bow(text)\n",
    "xyz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1134,
     "status": "ok",
     "timestamp": 1549858527324,
     "user": {
      "displayName": "SURAJ PAWAR",
      "photoUrl": "https://lh3.googleusercontent.com/-AyjYqK2CgTs/AAAAAAAAAAI/AAAAAAAAAi0/7DFu2E8Fno8/s64/photo.jpg",
      "userId": "15683806829583900212"
     },
     "user_tz": -330
    },
    "id": "RzV4S0j5tE_J",
    "outputId": "87872777-0f82-432e-8b42-a65834e14848"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "allsentences = [\"Joe waited for the train train\", \"The train was late\", \"Mary and Samantha took the bus\",\n",
    "\"I looked for Mary and Samantha at the bus station\",\n",
    "\"Mary and Samantha arrived at the bus station early but waited until noon for the bus\"]\n",
    "vocab = generate_bow(allsentences)\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1148,
     "status": "ok",
     "timestamp": 1549858575052,
     "user": {
      "displayName": "SURAJ PAWAR",
      "photoUrl": "https://lh3.googleusercontent.com/-AyjYqK2CgTs/AAAAAAAAAAI/AAAAAAAAAi0/7DFu2E8Fno8/s64/photo.jpg",
      "userId": "15683806829583900212"
     },
     "user_tz": -330
    },
    "id": "os1qhlpmtJ9O",
    "outputId": "44c84451-8fee-4063-df0a-7d9357fd6cea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "bag_vector = numpy.zeros(len(vocab))\n",
    "print(bag_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1146,
     "status": "ok",
     "timestamp": 1549858714230,
     "user": {
      "displayName": "SURAJ PAWAR",
      "photoUrl": "https://lh3.googleusercontent.com/-AyjYqK2CgTs/AAAAAAAAAAI/AAAAAAAAAi0/7DFu2E8Fno8/s64/photo.jpg",
      "userId": "15683806829583900212"
     },
     "user_tz": -330
    },
    "id": "MRyI8Oisxcxw",
    "outputId": "b53e06ef-2e8a-4318-8cd3-11a605516903"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 2 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1]\n",
      " [1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0]\n",
      " [1 0 1 1 0 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0]\n",
      " [1 1 1 2 1 1 1 0 0 0 1 1 1 1 2 0 0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(allsentences)\n",
    "\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2407,
     "status": "ok",
     "timestamp": 1549858852193,
     "user": {
      "displayName": "SURAJ PAWAR",
      "photoUrl": "https://lh3.googleusercontent.com/-AyjYqK2CgTs/AAAAAAAAAAI/AAAAAAAAAi0/7DFu2E8Fno8/s64/photo.jpg",
      "userId": "15683806829583900212"
     },
     "user_tz": -330
    },
    "id": "aehcMF16x5n4",
    "outputId": "773540da-c517-4bbb-f81b-335583ce9b1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word List for Document \n",
      "['and', 'arrived', 'at', 'bus', 'but', 'early', 'for', 'i', 'joe', 'late', 'looked', 'mary', 'noon', 'samantha', 'station', 'the', 'took', 'train', 'until', 'waited', 'was'] \n",
      "\n",
      "Joe waited for the train \n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.]\n",
      "\n",
      "The train was late \n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1.]\n",
      "\n",
      "Mary and Samantha took the bus \n",
      "[1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      "\n",
      "I looked for Mary and Samantha at the bus station \n",
      "[1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "Mary and Samantha arrived at the bus station early but waited until noon for the bus \n",
      "[1. 1. 1. 2. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import statments\n",
    "import numpy\n",
    "import re\n",
    "\n",
    "'''\n",
    "Tokenize each the sentences, example\n",
    "Input : \"John likes to watch movies. Mary likes movies too\"\n",
    "Ouput : \"John\",\"likes\",\"to\",\"watch\",\"movies\",\"Mary\",\"likes\",\"movies\",\"too\"\n",
    "'''\n",
    "def tokenize(sentences):\n",
    "    words = []\n",
    "    for sentence in sentences:\n",
    "        w = word_extraction(sentence)\n",
    "        words.extend(w)\n",
    "        \n",
    "    words = sorted(list(set(words)))\n",
    "    return words\n",
    "\n",
    "def word_extraction(sentence):\n",
    "    ignore = ['a', \"the\", \"is\"]\n",
    "    words = re.sub(\"[^\\w]\", \" \",  sentence).split()\n",
    "    cleaned_text = [w.lower() for w in words if w not in ignore]\n",
    "    return cleaned_text    \n",
    "    \n",
    "def generate_bow(allsentences):    \n",
    "    vocab = tokenize(allsentences)\n",
    "    print(\"Word List for Document \\n{0} \\n\".format(vocab));\n",
    "\n",
    "    for sentence in allsentences:\n",
    "        words = word_extraction(sentence)\n",
    "        bag_vector = numpy.zeros(len(vocab))\n",
    "        for w in words:\n",
    "            for i,word in enumerate(vocab):\n",
    "                if word == w: \n",
    "                    bag_vector[i] += 1\n",
    "                    \n",
    "        print(\"{0} \\n{1}\\n\".format(sentence,numpy.array(bag_vector)))\n",
    "\n",
    "\n",
    "allsentences = [\"Joe waited for the train\", \"The train was late\", \"Mary and Samantha took the bus\", \n",
    "            \"I looked for Mary and Samantha at the bus station\", \n",
    "            \"Mary and Samantha arrived at the bus station early but waited until noon for the bus\"]\n",
    "\n",
    "\n",
    "generate_bow(allsentences)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of bag_of_word_demo.ipynb",
   "provenance": [
    {
     "file_id": "1eBu9OlIwvONgVPLKKfdaaoruXbQ83fep",
     "timestamp": 1549859935502
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
